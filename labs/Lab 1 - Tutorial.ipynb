{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from preamble import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab 1: Machine Learning with Python\n",
    "Joaquin Vanschoren, Pieter Gijsbers, Bilge Celik, Prabhant Singh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "* Why Python?\n",
    "* Intro to scikit-learn\n",
    "* Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Python?\n",
    "* Many data-heavy applications are now developed in Python\n",
    "* Highly readable, less complexity, fast prototyping\n",
    "* Easy to offload number crunching to underlying C/Fortran/... \n",
    "* Easy to install and import many rich libraries\n",
    "    - numpy: efficient data structures\n",
    "    - scipy: fast numerical recipes\n",
    "    - matplotlib: high-quality graphs\n",
    "    - scikit-learn: machine learning algorithms\n",
    "    - tensorflow: neural networks\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/tut_ecosystem.jpg\" alt=\"ml\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Numpy, Scipy, Matplotlib\n",
    "* See the tutorials (in the course GitHub)\n",
    "* Many good tutorials online\n",
    "    - [Jake VanderPlas' book and notebooks](https://github.com/jakevdp/PythonDataScienceHandbook)\n",
    "    - [J.R. Johansson's notebooks](https://github.com/jrjohansson/scientific-python-lectures)\n",
    "    - [DataCamp](https://www.datacamp.com)\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# scikit-learn\n",
    "One of the most prominent Python libraries for machine learning:\n",
    "\n",
    "* Contains many state-of-the-art machine learning algorithms\n",
    "* Builds on numpy (fast), implements advanced techniques\n",
    "* Wide range of evaluation measures and techniques\n",
    "* Offers [comprehensive documentation](http://scikit-learn.org/stable/documentation) about each algorithm\n",
    "* Widely used, and a wealth of [tutorials](http://scikit-learn.org/stable/user_guide.html) and code snippets are available \n",
    "* Works well with numpy, scipy, pandas, matplotlib,..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Algorithms\n",
    "See the [Reference](http://scikit-learn.org/dev/modules/classes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Supervised learning:__\n",
    "\n",
    "* Linear models (Ridge, Lasso, Elastic Net, ...)\n",
    "* Support Vector Machines\n",
    "* Tree-based methods (Classification/Regression Trees, Random Forests,...)\n",
    "* Nearest neighbors\n",
    "* Neural networks \n",
    "* Gaussian Processes\n",
    "* Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Unsupervised learning:__\n",
    "    \n",
    "* Clustering (KMeans, ...)\n",
    "* Matrix Decomposition (PCA, ...)\n",
    "* Manifold Learning (Embeddings)\n",
    "* Density estimation\n",
    "* Outlier detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "__Model selection and evaluation:__\n",
    "\n",
    "* Cross-validation\n",
    "* Grid-search\n",
    "* Lots of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data import\n",
    "Multiple options:\n",
    "\n",
    "* A few toy datasets are included in `sklearn.datasets`\n",
    "* Import [1000s of datasets](http://www.openml.org) via `sklearn.datasets.fetch_openml`\n",
    "* You can import data files (CSV) with `pandas` or `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris, fetch_openml\n",
    "iris_data = load_iris()\n",
    "dating_data = fetch_openml(\"SpeedDating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will return a `Bunch` object (similar to a `dict`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of iris_dataset: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, pre\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys of iris_dataset: {}\".format(iris_data.keys()))\n",
    "print(iris_data['DESCR'][:193] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Targets (classes) and features are lists of strings\n",
    "* Data and target values are always numeric (ndarrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: ['setosa' 'versicolor' 'virginica']\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Shape of data: (150, 4)\n",
      "First 5 rows:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Targets:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Targets: {}\".format(iris_data['target_names']))\n",
    "print(\"Features: {}\".format(iris_data['feature_names']))\n",
    "print(\"Shape of data: {}\".format(iris_data['data'].shape))\n",
    "print(\"First 5 rows:\\n{}\".format(iris_data['data'][:5]))\n",
    "print(\"Targets:\\n{}\".format(iris_data['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building models\n",
    "All scikitlearn _estimators_ follow the same interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SupervisedEstimator(...):\n",
    "    def __init__(self, hyperparam, ...):\n",
    "\n",
    "    def fit(self, X, y):   # Fit/model the training data\n",
    "        ...                # given data X and targets y\n",
    "        return self\n",
    "     \n",
    "    def predict(self, X):  # Make predictions\n",
    "        ...                # on unseen data X  \n",
    "        return y_pred\n",
    "    \n",
    "    def score(self, X, y): # Predict and compare to true\n",
    "        ...                # labels y                \n",
    "        return score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training and testing data\n",
    "To evaluate our classifier, we need to test it on unseen data.  \n",
    "`train_test_split`: splits data randomly in 75% training and 25% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris_data['data'], iris_data['target'], \n",
    "    random_state=0)\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also choose other ways to split the data. For instance, the following will create a training set of 10% of the data and a test set of 5% of the data. This is useful when dealing with very large datasets. `stratify` defines the target feature to stratify the data (ensure that the class distributions are kept the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris_data['data'], iris_data['target']\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(X,y, stratify=y, train_size=0.1, test_size=0.05)\n",
    "print(\"Xs_train shape: {}\".format(Xs_train.shape))\n",
    "print(\"Xs_test shape: {}\".format(Xs_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Looking at your data (with pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Build a DataFrame with training examples and feature names\n",
    "iris_df = pd.DataFrame(X_train, \n",
    "                       columns=iris_data.feature_names)\n",
    "\n",
    "# scatter matrix from the dataframe, color by class\n",
    "sm = scatter_matrix(iris_df, c=y_train, figsize=(8, 8), \n",
    "                  marker='o', hist_kwds={'bins': 20}, s=60, \n",
    "                  alpha=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we'll build is a k-Nearest Neighbor classifier.  \n",
    "kNN is included in `sklearn.neighbors`, so let's build our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making predictions\n",
    "Let's create a new example and ask the kNN model to classify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "prediction = knn.predict(X_new)\n",
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Predicted target name: {}\".format(\n",
    "       iris_data['target_names'][prediction]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating the model\n",
    "Feeding all test examples to the model yields all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `score` function computes the percentage of correct predictions\n",
    "\n",
    "``` python\n",
    "knn.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Score: {:.2f}\".format(knn.score(X_test, y_test) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of a single train-test split, we can use `cross_validate` do run a cross-validation. \n",
    "It will return the test scores, as well as the fit and score times, for every fold.\n",
    "By default, scikit-learn does a 5-fold cross-validation, hence returning 5 test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.001, 0.001, 0.001, 0.001, 0.001]),\n",
       " 'score_time': array([0.001, 0.001, 0.001, 0.001, 0.001]),\n",
       " 'test_score': array([0.967, 0.967, 0.933, 0.933, 1.   ]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "xval = cross_validate(knn, X, y, return_train_score=True, n_jobs=-1)\n",
    "xval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean should give a better performance estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xval['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introspecting the model\n",
    "Most models allow you to retrieve the trained model parameters, usually called `coef_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.153, -0.025,  0.267,  0.574])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching these with the names of the features, we can see which features are primarily used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('petal length (cm)', 0.2669801292888398),\n",
       " ('petal width (cm)', 0.5738618608875328),\n",
       " ('sepal length (cm)', -0.15330145645467907),\n",
       " ('sepal width (cm)', -0.02540761074550385)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = zip(iris_data.feature_names,lr.coef_)\n",
    "set(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please see the course notebooks for more examples on how to analyse models."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_metadata": {
   "author": "Joaquin Vanschoren",
   "title": "Introduction"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
